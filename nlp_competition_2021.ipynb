{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_competition_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshajbansal/hindi_to_english_translator/blob/main/nlp_competition_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uk9KQzlu_2J"
      },
      "source": [
        "Please refer to competition report submitted for detailed analysis of the model and the citations used for this model. The main citations have been included in this code itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzMGWiWuVzDP",
        "outputId": "3f30dbdd-d648-4097-b4e5-648141cb67ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSTdvfUE2be-"
      },
      "source": [
        "#importing modules required in the model\n",
        "import csv\n",
        "#for reading csv file (Note csv is in-built module and not an external library which needs to be installed)\n",
        "\n",
        "from spacy.lang.en import English\n",
        "#for preprocessing english language\n",
        "\n",
        "from io import open     #for file management\n",
        "import sys, unicodedata, string, re, random, torch, math    #other important modules\n",
        "\n",
        "#including necessary torch functionalities\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#including matplotlib for plotting graph\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-V5jPQ0yF9C"
      },
      "source": [
        "def read_csv(path):\n",
        "    with open(path, 'r') as file:         #open csv file at location path\n",
        "        my_reader = csv.reader(file, delimiter=',')\n",
        "        cnt = 0\n",
        "        for row in my_reader:\n",
        "            if cnt == 0:    cnt += 1        #skips reading headers from csv file\n",
        "            else:\n",
        "                if str(path) == train_path:     #if train_path is argument\n",
        "                    array.append([row[1], row[2]])       #row[0] is index, row[1] is hindi, row[2] is english\n",
        "                    cnt += 1\n",
        "                else:                           #if test_path is argument\n",
        "                    sentences.append(row[2])       #row[0] is index, row[1] is index, row[2] is hindi\n",
        "                    cnt += 1\n",
        "    return cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqDy25DhvoxR"
      },
      "source": [
        "#array to store hindi-english sentence pairs\n",
        "array = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w76FRL13sBad",
        "outputId": "1e986391-ba56-461b-b2f5-ead2ab87dd47"
      },
      "source": [
        "#importing train data from csv file\n",
        "train_path = 'drive/MyDrive/train.csv'\n",
        "cnt = read_csv(train_path)\n",
        "print(f'{cnt-1} sentences read')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102322 sentences read\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMX1t1eXTUKQ"
      },
      "source": [
        "#below line is for specifying number of train pairs to be sampled randomly\n",
        "#array = random.sample(array, 45000)     #sample 45000 data pairs randomly\n",
        "#since the above line is commented, all data pairs are read\n",
        "data_hindi = []     #array to store hindi sentences\n",
        "data_english = []       #array to store english sentences\n",
        "for i in array:     #splits hindi and english sentences\n",
        "    data_hindi.append(i[0])\n",
        "    data_english.append(i[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGnGjTQwNZP-",
        "outputId": "6cf84988-bcaa-4357-c3a7-998299e677e3"
      },
      "source": [
        "print(len(data_hindi), len(data_english))\n",
        "print(data_hindi[:10])\n",
        "print(data_english[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102322 102322\n",
            "['एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध से वापसी ली, उन्होंने वही काम किये जो कैदियों की कश्मकश के निदान हैं।', 'मैं उनके साथ कोई लेना देना नहीं है.', '-हटाओ रिक.', 'क्योंकि यह एक खुशियों भरी फ़िल्म है.', 'The thought reaching the eyes...', 'मैंने तुमे School से हटवा दिया .', 'यह Vika, एक फूल है.', 'पर मेरे लिए उसका यहुदी विरोधी होना उसके कार्यों को और भी प्रशंसनीय बनाता है क्योंकि उसके पास भी पक्षपात करने के वही कारण थे जो बाकी फौजियों के पास थे पर उसकी सच जानने और उसे बनाए रखने की प्रेरणा सबसे ऊपर थी', 'नहीं, नहीं, नहीं... ठीक है, हम उह हूँ... हम कार्ड का उपयोग करेंगे.', '- क्या भाषा क्या वे वहाँ बात की?']\n",
            "[\"In El Salvador, both sides that withdrew from their civil war took moves that had been proven to mirror a prisoner's dilemma strategy.\", 'I have nothing to do with them.', 'Fuck them, Rick.', \"Because it's a happy film.\", 'The thought reaching the eyes...', 'I got you suspended.', \"It's a flower, Vika.\", 'But personally, for me, the fact that Picquart was anti-Semitic actually makes his actions more admirable, because he had the same prejudices, the same reasons to be biased as his fellow officers, but his motivation to find the truth and uphold it trumped all of that.', \"No, no, no... fine, we'll uh... we'll use the card.\", '- What language do they speak there?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pu7HRI52i0m",
        "outputId": "9889eb32-d91f-40c7-e37a-b60dce36e205"
      },
      "source": [
        "#installing and cloning required items for preprocessing\n",
        "get_ipython().system('pip install Morfessor')     #Morfessor models Indian languages\n",
        "\n",
        "#this is the citation for the indicnlp library and resources used\n",
        "#@misc{\n",
        "#  kunchukuttan2020indicnlp,\n",
        "#  author = \"Anoop Kunchukuttan\",\n",
        "#  title = \"{The IndicNLP Library}\",\n",
        "#  year = \"2020\",\n",
        "#  howpublished={\\url{https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/docs/indicnlp.pdf}}\n",
        "#}\n",
        "#this citation is given on the webpage which can be accessed by the above/below link\n",
        "\n",
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\"\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "INDIC_NLP_LIB_HOME = r\"/content/indic_nlp_library\"\n",
        "INDIC_NLP_RESOURCES = \"/content/indic_nlp_resources\"\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1271, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 16.56 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 42.56 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3QaWUA2iyp"
      },
      "source": [
        "#importing relevant items from indicnlp\n",
        "from indicnlp import loader\n",
        "from indicnlp import common\n",
        "from indicnlp.tokenize import indic_tokenize \n",
        "from indicnlp.normalize.indic_normalize import BaseNormalizer\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5c7zBiBj2z1"
      },
      "source": [
        "#enabling cuda for this model\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLgAAqRf2iur"
      },
      "source": [
        "#tokenizing English using spacy module of python\n",
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAdI9JC52itE"
      },
      "source": [
        "#defining variables\n",
        "SOS, EOS, UKN = 0, 1, 2     #start of sentence, end of sentence, unknown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWh-62Xo2iqU"
      },
      "source": [
        "#tokenize a sentence\n",
        "#using spacy for english and INDICNLP for hindi\n",
        "def tokenize_sentence(lang, s):\n",
        "    return list(tokenizer(s)) if lang.name == 'English' else list(indic_tokenize.trivial_tokenize(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI3BDGXY2ipp"
      },
      "source": [
        "#create indices\n",
        "#returns index of word in the list if word is found\n",
        "#returns 2 (the variable index for UKN) if word is not found\n",
        "def sentence_indices(lang, s):\n",
        "    return [lang.word2index.get(str(i),2) for i in list(tokenizer(s))] if lang.name == 'English' else [lang.word2index.get(i, 2) for i in list(indic_tokenize.trivial_tokenize(s))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ah6wVWV2imd"
      },
      "source": [
        "#creating variables\n",
        "#returns array of indices\n",
        "def sentence_variables(lang, s):\n",
        "    index = sentence_indices(lang, s)\n",
        "    index.append(EOS)\n",
        "    return Variable(torch.LongTensor(index).view(-1, 1)).cuda() if use_cuda else Variable(torch.LongTensor(index).view(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB-WqYEx2ilT"
      },
      "source": [
        "#creating hindi-english data pairs\n",
        "#returns hindi-english pairs\n",
        "def pair_variables(hindi_language, english_language, pair):\n",
        "    return (sentence_variables(hindi_language, pair[0]), sentence_variables(english_language, pair[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2sFOs4-2iiH"
      },
      "source": [
        "#creating class Create_Language\n",
        "class Create_Language:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.vocab = 3      #dictionary size (initially 3: SOS, EOS, UKN)\n",
        "        self.word2index = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UKN\"}   #start of sentence, end of sentence, unknown\n",
        "\n",
        "    def add_word(self, word):      #adds new word to dictionary\n",
        "        if word not in self.word2index:\n",
        "            self.vocab += 1\n",
        "            self.word2index[word] = self.vocab-1\n",
        "            self.index2word[self.vocab-1] = word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSRkOqkL2igv"
      },
      "source": [
        "#preparing dictionary\n",
        "#returns training data pairs\n",
        "def dictionary(data_hindi, data_english):\n",
        "    hindi_language, english_language = Create_Language('Hindi'), Create_Language('English')     #creates language\n",
        "    hindi_sentences, english_sentences = list(data_hindi), list(data_english)     #data from csv file splitted into hindi and english\n",
        "    train_data_pairs = list(zip(hindi_sentences, english_sentences))        #hindi-english corresponding sentence pairing\n",
        "\n",
        "    for hindi_sentence, english_sentence in train_data_pairs:       #tokenize sentences and adding words to vocabulary/dictionary\n",
        "        for token in tokenize_sentence(hindi_language, hindi_sentence):      hindi_language.add_word(token)\n",
        "        for token in tokenize_sentence(english_language, english_sentence):      english_language.add_word(str(token))\n",
        "  \n",
        "    print(f'English has {english_language.vocab} words\\nHindi has {hindi_language.vocab} words')\n",
        "    return hindi_language, english_language, train_data_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNDTcE2M2idT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303097b8-aa0a-46c9-b561-4f828ce75b8b"
      },
      "source": [
        "hindi_language, english_language, train_data_pairs = dictionary(data_hindi, data_english)       #displaying number of words read"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English has 38349 words\n",
            "Hindi has 46383 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOCVDevR2ibn"
      },
      "source": [
        "#Encoder Module\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, layers = 1):    #number of layers = 1\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layers = layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        for i in range(self.layers):     output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
        "        return result.cuda() if use_cuda else result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7YhiwwZ3I9T"
      },
      "source": [
        "#Decoder Module\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, layers = 1):       #number of layers = 1\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layers = layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        for i in range(self.layers):\n",
        "            output = F.relu(output)\n",
        "            output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
        "        return result.cuda() if use_cuda else result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHD4f5B03I6e"
      },
      "source": [
        "#initializing encoder and decoder\n",
        "hidden_size = 1024\n",
        "encoder = Encoder(hindi_language.vocab, hidden_size)\n",
        "decoder = Decoder(hidden_size, english_language.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azeufV-w3I3I"
      },
      "source": [
        "#using cuda for encoder and decoder\n",
        "if use_cuda:      #torch.cuda is available for use\n",
        "    encoder = encoder.cuda()\n",
        "    decoder = decoder.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2w1fBS33eYi"
      },
      "source": [
        "#parameters for train data function\n",
        "teacher_forcing_ratio = 0.6\n",
        "MAX_LENGTH = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3sUNoGh3I16"
      },
      "source": [
        "#training data function\n",
        "def train(input_variable, output_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length = MAX_LENGTH):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_variable.size()[0]\n",
        "    target_length = output_variable.size()[0]\n",
        "\n",
        "    encoder_outputs = Variable(torch.zeros(input_length, encoder.hidden_size)).cuda() if use_cuda else Variable(torch.zeros(input_length, encoder.hidden_size))\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    #training encoder\n",
        "    for en_in in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_variable[en_in], encoder_hidden)\n",
        "        encoder_outputs[en_in] = encoder_output[0][0]\n",
        "\n",
        "    decoder_input = Variable(torch.LongTensor([[SOS]])).cuda() if use_cuda else Variable(torch.LongTensor([[SOS]]))\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    #training decoder based on teacher_forcing_ratio\n",
        "    if teacher_forcing:         #target output serves as next input\n",
        "        for de_in in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, output_variable[de_in])\n",
        "            decoder_input = output_variable[de_in]\n",
        "    else:        #prediction word serves as next input\n",
        "        for de_in in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            d1, d2 = decoder_output.data.topk(1)\n",
        "            decoder_input = Variable(torch.LongTensor([[d2[0][0]]])).cuda() if use_cuda else Variable(torch.LongTensor([[d2[0][0]]]))\n",
        "            loss += criterion(decoder_output, output_variable[de_in])\n",
        "            if d2[0][0] == EOS:   break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBYAvFFE3IyP"
      },
      "source": [
        "#model parameteres and some declarations\n",
        "learning_rate = 0.006\n",
        "#losses array is to record loss values per batch_size iterations so that they can be plotted later\n",
        "losses = []\n",
        "total_loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzW33aXM-PTm"
      },
      "source": [
        "#number of iterations for train phase\n",
        "iterations = 12800\n",
        "#number of epochs for train phase\n",
        "epochs = 10\n",
        "batch_size = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5augyoj3IwU"
      },
      "source": [
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
        "train_data_pairs = random.sample(train_data_pairs, iterations)\n",
        "training_pairs = [pair_variables(hindi_language, english_language, train_data_pairs[iter]) for iter in range(iterations)]      #randomly selects 12800 data pairs\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VMLtQctZm89"
      },
      "source": [
        "#function to calculate loss for training phase of the model\n",
        "def calculate_loss(iter, batch_size):\n",
        "    training_pair = training_pairs[iter]\n",
        "    input_variable, output_variable = training_pair[0], training_pair[1]\n",
        "    loss = train(input_variable, output_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1JOBD_O3Yif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "10642249-2975-4f54-8fea-bf9f9cec7bff"
      },
      "source": [
        "#training phase for the model\n",
        "#note that this model trains on 1 data per iteration for 12800 iterations using SGD for 10 epochs\n",
        "for epoch in range(epochs):     #number of epochs\n",
        "    if epoch == 4:      #early stopping since loss increases afterwards\n",
        "        break\n",
        "    print(f'Epoch {epoch+1}:')\n",
        "    for iter in range(iterations):      #iterations = 12800 per epoch\n",
        "        total_loss += calculate_loss(iter, batch_size)\n",
        "        if (iter+1) % batch_size == 0:      #calculates average loss per batch_size = 400 iterations\n",
        "            avg_loss = total_loss / batch_size\n",
        "            losses.append(avg_loss)\n",
        "            total_loss = 0\n",
        "            print(f'    Iterations ({iter+1}/{iterations}) have an average loss of {avg_loss}')\n",
        "    plt.plot(losses)        #plots points on graph and connects them sequentially for each epoch\n",
        "    losses = []         #losses array again initialized to [] for next epoch\n",
        "    #comment above line if you want cotinuous plot of loss function and not loss per epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "    Iterations (400/12800) have an average loss of 3.556526342712778\n",
            "    Iterations (800/12800) have an average loss of 3.6408736333183556\n",
            "    Iterations (1200/12800) have an average loss of 3.63722895823655\n",
            "    Iterations (1600/12800) have an average loss of 3.492270237183564\n",
            "    Iterations (2000/12800) have an average loss of 3.6894716835042396\n",
            "    Iterations (2400/12800) have an average loss of 3.6188794738283083\n",
            "    Iterations (2800/12800) have an average loss of 3.530993393659386\n",
            "    Iterations (3200/12800) have an average loss of 3.38150592900412\n",
            "    Iterations (3600/12800) have an average loss of 3.7084702504942486\n",
            "    Iterations (4000/12800) have an average loss of 3.487055985770064\n",
            "    Iterations (4400/12800) have an average loss of 3.603846483180705\n",
            "    Iterations (4800/12800) have an average loss of 3.4356631166074942\n",
            "    Iterations (5200/12800) have an average loss of 3.493178861771633\n",
            "    Iterations (5600/12800) have an average loss of 3.649798981984272\n",
            "    Iterations (6000/12800) have an average loss of 3.6489533562817487\n",
            "    Iterations (6400/12800) have an average loss of 3.49502422033818\n",
            "    Iterations (6800/12800) have an average loss of 3.5486020239926437\n",
            "    Iterations (7200/12800) have an average loss of 3.598766572466122\n",
            "    Iterations (7600/12800) have an average loss of 3.6748789122008554\n",
            "    Iterations (8000/12800) have an average loss of 3.560849527500034\n",
            "    Iterations (8400/12800) have an average loss of 3.6161563025684753\n",
            "    Iterations (8800/12800) have an average loss of 3.532437991836943\n",
            "    Iterations (9200/12800) have an average loss of 3.5530112330271892\n",
            "    Iterations (9600/12800) have an average loss of 3.725678018114718\n",
            "    Iterations (10000/12800) have an average loss of 3.652643475926061\n",
            "    Iterations (10400/12800) have an average loss of 3.530803329382065\n",
            "    Iterations (10800/12800) have an average loss of 3.7883198844667305\n",
            "    Iterations (11200/12800) have an average loss of 3.9856738856232283\n",
            "    Iterations (11600/12800) have an average loss of 3.8912543035169667\n",
            "    Iterations (12000/12800) have an average loss of 4.034800454767876\n",
            "    Iterations (12400/12800) have an average loss of 3.944282137942795\n",
            "    Iterations (12800/12800) have an average loss of 3.944701023342033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB3OYypy3YZ3"
      },
      "source": [
        "#function for testing data\n",
        "def evaluate(encoder, decoder, sentence, max_length = MAX_LENGTH):\n",
        "    input_variable = sentence_variables(hindi_language, sentence)\n",
        "    input_length = input_variable.size()[0]\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_outputs = Variable(torch.zeros(input_length, encoder.hidden_size)).cuda() if use_cuda else Variable(torch.zeros(input_length, encoder.hidden_size))\n",
        "\n",
        "    #test input enters encoder\n",
        "    for en_in in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_variable[en_in], encoder_hidden)\n",
        "        encoder_outputs[en_in] += encoder_output[0][0]\n",
        "\n",
        "    decoder_input = Variable(torch.LongTensor([[SOS]])).cuda() if use_cuda else Variable(torch.LongTensor([[SOS]]))\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoded_words = []\n",
        "\n",
        "    #test input enters decoder\n",
        "    for de_in in range(max_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        d1, d2 = decoder_output.data.topk(1)\n",
        "        if d2[0][0].item() != EOS:\n",
        "            decoded_words.append(english_language.index2word[d2[0][0].item()])\n",
        "        else:\n",
        "            break\n",
        "        decoder_input = Variable(torch.LongTensor([[d2[0][0].item()]])).cuda() if use_cuda else Variable(torch.LongTensor([[d2[0][0].item()]]))\n",
        "\n",
        "    return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOlt_H0z5koL"
      },
      "source": [
        "#computing output using evaluate and store the result in translation\n",
        "def compute_translation(sentences):\n",
        "    translation = \"\"     #stores translated sentences in output with each sentence separated by \\n character\n",
        "    for sentence in sentences:\n",
        "        translated_sentence = ' '.join(evaluate(encoder, decoder, sentence))\n",
        "        translated_sentence += \"\\n\"\n",
        "        translation += translated_sentence\n",
        "    return translation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ-6Zgsc3YKv"
      },
      "source": [
        "#writes output to answer.txt\n",
        "def write_output(output_path, translation):\n",
        "    f = open(output_path,\"w\")\n",
        "    f.write(translation)\n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZNTbNgAoMtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9a0c68-045d-4351-d3a5-e57d98104fc8"
      },
      "source": [
        "#test phase of the model\n",
        "test_path = 'drive/MyDrive/testhindistatements.csv'\n",
        "\n",
        "sentences = []\n",
        "cnt = read_csv(test_path)\n",
        "print(f'{cnt-1} sentences read')\n",
        "\n",
        "translation = compute_translation(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24102 sentences read\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quv_1-Cjz-ZS",
        "outputId": "e0f5c28f-fba9-44df-d58b-357e6045f450"
      },
      "source": [
        "print(sentences[:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['(तालियां) अब, इसने मेरे मन को उड़ा दिया।', 'पर आप बहुत धाँसू लग रहे हैं।', 'शास्त्र समझ्ने के रा स्ते बनाती है|', 'कृपया मेरी बात सुनो।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prF180Ld5kgD"
      },
      "source": [
        "output_path = 'answer.txt'\n",
        "write_output(output_path, translation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JGH2Es1aPzV"
      },
      "source": [
        "#saving encoder and decoder model used for training\n",
        "model = 'encoder.pt'\n",
        "path = F\"/content/drive/MyDrive/{model}\" \n",
        "torch.save(encoder.state_dict(), path)\n",
        "model = 'decoder.pt'\n",
        "path = F\"/content/drive/MyDrive/{model}\" \n",
        "torch.save(decoder.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLtq1-5tr0nc"
      },
      "source": [
        "I would like to cite the following webpage from which I took help to write the above code:\n",
        "\n",
        "S.R. (2017). NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION. Pytorch.Org. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\n",
        "I would like to mention that I have used some parts from the above source and modified them according to my needs. Moreover, the above source used attention decoder which I did not use in my model. However, the encoder and decoder module which I implemented are quite similar in their functionality because I used the same architecture as the webpage: GRU, ReLu, softmax and NLL loss. I could not try other functions because the model took a large time to run and I also had to find the best hyperparameters for the model.\n",
        "\n",
        "I also used python documentations for pytorch and other stuffs from the main python documentation webpage."
      ]
    }
  ]
}